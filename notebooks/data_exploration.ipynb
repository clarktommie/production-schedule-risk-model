{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34bc6223",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "55ec4632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff3500",
   "metadata": {},
   "source": [
    "## SET DATA PATH TO ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1d40f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Resolve project root (one level above notebooks/)\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "RAW_DATA_PATH = PROJECT_ROOT / \"data\" / \"hybrid_manufacturing_categorical.csv\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "761fdcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_ID</th>\n",
       "      <th>Machine_ID</th>\n",
       "      <th>Operation_Type</th>\n",
       "      <th>Material_Used</th>\n",
       "      <th>Processing_Time</th>\n",
       "      <th>Energy_Consumption</th>\n",
       "      <th>Machine_Availability</th>\n",
       "      <th>Scheduled_Start</th>\n",
       "      <th>Scheduled_End</th>\n",
       "      <th>Actual_Start</th>\n",
       "      <th>Actual_End</th>\n",
       "      <th>Job_Status</th>\n",
       "      <th>Optimization_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J001</td>\n",
       "      <td>M01</td>\n",
       "      <td>Grinding</td>\n",
       "      <td>3.17</td>\n",
       "      <td>76</td>\n",
       "      <td>11.42</td>\n",
       "      <td>96</td>\n",
       "      <td>2023-03-18 08:00:00</td>\n",
       "      <td>2023-03-18 09:16:00</td>\n",
       "      <td>2023-03-18 08:05:00</td>\n",
       "      <td>2023-03-18 09:21:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Moderate Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J002</td>\n",
       "      <td>M01</td>\n",
       "      <td>Grinding</td>\n",
       "      <td>3.35</td>\n",
       "      <td>79</td>\n",
       "      <td>6.61</td>\n",
       "      <td>84</td>\n",
       "      <td>2023-03-18 08:10:00</td>\n",
       "      <td>2023-03-18 09:29:00</td>\n",
       "      <td>2023-03-18 08:20:00</td>\n",
       "      <td>2023-03-18 09:39:00</td>\n",
       "      <td>Delayed</td>\n",
       "      <td>Low Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J003</td>\n",
       "      <td>M04</td>\n",
       "      <td>Additive</td>\n",
       "      <td>2.29</td>\n",
       "      <td>56</td>\n",
       "      <td>11.11</td>\n",
       "      <td>92</td>\n",
       "      <td>2023-03-18 08:20:00</td>\n",
       "      <td>2023-03-18 09:16:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Low Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J004</td>\n",
       "      <td>M04</td>\n",
       "      <td>Grinding</td>\n",
       "      <td>1.76</td>\n",
       "      <td>106</td>\n",
       "      <td>12.50</td>\n",
       "      <td>95</td>\n",
       "      <td>2023-03-18 08:30:00</td>\n",
       "      <td>2023-03-18 10:16:00</td>\n",
       "      <td>2023-03-18 08:35:00</td>\n",
       "      <td>2023-03-18 10:21:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Moderate Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J005</td>\n",
       "      <td>M01</td>\n",
       "      <td>Lathe</td>\n",
       "      <td>1.90</td>\n",
       "      <td>46</td>\n",
       "      <td>8.13</td>\n",
       "      <td>88</td>\n",
       "      <td>2023-03-18 08:40:00</td>\n",
       "      <td>2023-03-18 09:26:00</td>\n",
       "      <td>2023-03-18 08:42:00</td>\n",
       "      <td>2023-03-18 09:28:00</td>\n",
       "      <td>Completed</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Job_ID Machine_ID Operation_Type  Material_Used  Processing_Time  \\\n",
       "0   J001        M01       Grinding           3.17               76   \n",
       "1   J002        M01       Grinding           3.35               79   \n",
       "2   J003        M04       Additive           2.29               56   \n",
       "3   J004        M04       Grinding           1.76              106   \n",
       "4   J005        M01          Lathe           1.90               46   \n",
       "\n",
       "   Energy_Consumption  Machine_Availability      Scheduled_Start  \\\n",
       "0               11.42                    96  2023-03-18 08:00:00   \n",
       "1                6.61                    84  2023-03-18 08:10:00   \n",
       "2               11.11                    92  2023-03-18 08:20:00   \n",
       "3               12.50                    95  2023-03-18 08:30:00   \n",
       "4                8.13                    88  2023-03-18 08:40:00   \n",
       "\n",
       "         Scheduled_End         Actual_Start           Actual_End Job_Status  \\\n",
       "0  2023-03-18 09:16:00  2023-03-18 08:05:00  2023-03-18 09:21:00  Completed   \n",
       "1  2023-03-18 09:29:00  2023-03-18 08:20:00  2023-03-18 09:39:00    Delayed   \n",
       "2  2023-03-18 09:16:00                  NaN                  NaN     Failed   \n",
       "3  2023-03-18 10:16:00  2023-03-18 08:35:00  2023-03-18 10:21:00  Completed   \n",
       "4  2023-03-18 09:26:00  2023-03-18 08:42:00  2023-03-18 09:28:00  Completed   \n",
       "\n",
       "  Optimization_Category  \n",
       "0   Moderate Efficiency  \n",
       "1        Low Efficiency  \n",
       "2        Low Efficiency  \n",
       "3   Moderate Efficiency  \n",
       "4       High Efficiency  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "raw_data_df = pd.read_csv(RAW_DATA_PATH)\n",
    "raw_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25240a0a",
   "metadata": {},
   "source": [
    "## Phase 1 - Operational Context\n",
    "\n",
    "This section quantifies baseline operational stability before modeling:\n",
    "\n",
    "- Delay rate (overall and by machine)\n",
    "- Schedule deviation distribution\n",
    "- Actual vs scheduled duration\n",
    "- Machine benchmark table (delay, efficiency, energy intensity)\n",
    "- Instability score to identify high-risk machines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9e9a9b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall delay rate: 48.50%\n",
      "\n",
      "Delay rate by machine (%):\n",
      "Machine_ID\n",
      "M05    51.30\n",
      "M02    48.57\n",
      "M03    48.39\n",
      "M01    47.64\n",
      "M04    46.73\n",
      "Name: delayed_flag, dtype: float64\n",
      "\n",
      "Schedule deviation distribution (min):\n",
      "count    871.00\n",
      "mean       4.47\n",
      "std        9.43\n",
      "min       -5.00\n",
      "25%       -2.00\n",
      "50%        1.00\n",
      "75%        5.00\n",
      "max       30.00\n",
      "Name: schedule_deviation_min, dtype: float64\n",
      "\n",
      "Actual vs scheduled duration summary:\n",
      "rows_with_both_durations     871.000\n",
      "scheduled_mean_min            71.316\n",
      "actual_mean_min               71.316\n",
      "avg_duration_delta_min         0.000\n",
      "median_duration_delta_min      0.000\n",
      "avg_duration_ratio             1.000\n",
      "dtype: float64\n",
      "\n",
      "Machine benchmark (most unstable first):\n",
      "            jobs  delay_rate_pct  avg_schedule_deviation_min  \\\n",
      "Machine_ID                                                     \n",
      "M05          193          51.295                       5.343   \n",
      "M03          186          48.387                       4.338   \n",
      "M04          199          46.734                       4.677   \n",
      "M01          212          47.642                       3.868   \n",
      "M02          210          48.571                       4.196   \n",
      "\n",
      "           avg_efficiency_category  energy_intensity  instability_score  \n",
      "Machine_ID                                                               \n",
      "M05                 Low Efficiency             0.120              3.521  \n",
      "M03                 Low Efficiency             0.125              1.187  \n",
      "M04            Moderate Efficiency             0.119             -0.878  \n",
      "M01            Moderate Efficiency             0.120             -1.699  \n",
      "M02            Moderate Efficiency             0.114             -2.131  \n"
     ]
    }
   ],
   "source": [
    "# Reuse already loaded dataset from earlier cells\n",
    "ops_df = raw_data_df.copy()\n",
    "\n",
    "# Parse datetime fields\n",
    "time_cols = ['Scheduled_Start', 'Scheduled_End', 'Actual_Start', 'Actual_End']\n",
    "for col in time_cols:\n",
    "    ops_df[col] = pd.to_datetime(ops_df[col], errors='coerce')\n",
    "\n",
    "# Derive timing metrics (minutes)\n",
    "ops_df['scheduled_duration_min'] = (ops_df['Scheduled_End'] - ops_df['Scheduled_Start']).dt.total_seconds() / 60\n",
    "ops_df['actual_duration_min'] = (ops_df['Actual_End'] - ops_df['Actual_Start']).dt.total_seconds() / 60\n",
    "ops_df['schedule_deviation_min'] = (ops_df['Actual_End'] - ops_df['Scheduled_End']).dt.total_seconds() / 60\n",
    "ops_df['start_delay_min'] = (ops_df['Actual_Start'] - ops_df['Scheduled_Start']).dt.total_seconds() / 60\n",
    "\n",
    "# Delay signal = explicit delayed status OR observed positive start/end slippage\n",
    "ops_df['delayed_flag'] = (\n",
    "    ops_df['Job_Status'].eq('Delayed')\n",
    "    | (ops_df['schedule_deviation_min'] > 0)\n",
    "    | (ops_df['start_delay_min'] > 0)\n",
    ")\n",
    "\n",
    "# 1) Delay rate (overall + machine)\n",
    "overall_delay_pct = ops_df['delayed_flag'].mean() * 100\n",
    "machine_delay_pct = (ops_df.groupby('Machine_ID')['delayed_flag'].mean() * 100).sort_values(ascending=False)\n",
    "\n",
    "print(f'Overall delay rate: {overall_delay_pct:.2f}%')\n",
    "print('\\nDelay rate by machine (%):')\n",
    "print(machine_delay_pct.round(2))\n",
    "\n",
    "# 2) Schedule deviation distribution\n",
    "deviation_min = ops_df['schedule_deviation_min'].dropna()\n",
    "print('\\nSchedule deviation distribution (min):')\n",
    "print(deviation_min.describe().round(2))\n",
    "\n",
    "# 3) Actual vs scheduled duration\n",
    "timed_jobs = ops_df.dropna(subset=['scheduled_duration_min', 'actual_duration_min']).copy()\n",
    "timed_jobs['duration_delta_min'] = timed_jobs['actual_duration_min'] - timed_jobs['scheduled_duration_min']\n",
    "\n",
    "duration_summary = pd.Series({\n",
    "    'rows_with_both_durations': len(timed_jobs),\n",
    "    'scheduled_mean_min': timed_jobs['scheduled_duration_min'].mean(),\n",
    "    'actual_mean_min': timed_jobs['actual_duration_min'].mean(),\n",
    "    'avg_duration_delta_min': timed_jobs['duration_delta_min'].mean(),\n",
    "    'median_duration_delta_min': timed_jobs['duration_delta_min'].median(),\n",
    "    'avg_duration_ratio': (timed_jobs['actual_duration_min'] / timed_jobs['scheduled_duration_min']).mean()\n",
    "}).round(3)\n",
    "\n",
    "print('\\nActual vs scheduled duration summary:')\n",
    "print(duration_summary)\n",
    "\n",
    "# 4) Machine benchmark table\n",
    "efficiency_score_map = {'Low Efficiency': 1, 'Moderate Efficiency': 2, 'High Efficiency': 3}\n",
    "efficiency_label_map = {1: 'Low Efficiency', 2: 'Moderate Efficiency', 3: 'High Efficiency'}\n",
    "ops_df['efficiency_score'] = ops_df['Optimization_Category'].map(efficiency_score_map)\n",
    "\n",
    "machine_kpis = ops_df.groupby('Machine_ID').agg(\n",
    "    jobs=('Job_ID', 'count'),\n",
    "    delay_rate_pct=('delayed_flag', lambda s: s.mean() * 100),\n",
    "    avg_schedule_deviation_min=('schedule_deviation_min', 'mean'),\n",
    "    avg_efficiency_score=('efficiency_score', 'mean'),\n",
    "    avg_energy=('Energy_Consumption', 'mean'),\n",
    "    avg_processing_time=('Processing_Time', 'mean')\n",
    ")\n",
    "machine_kpis['energy_intensity'] = machine_kpis['avg_energy'] / machine_kpis['avg_processing_time']\n",
    "machine_kpis['avg_efficiency_category'] = machine_kpis['avg_efficiency_score'].round().clip(1, 3).map(efficiency_label_map)\n",
    "\n",
    "# Composite instability score (higher = less stable)\n",
    "for col in ['delay_rate_pct', 'avg_schedule_deviation_min', 'energy_intensity']:\n",
    "    machine_kpis[f'{col}_z'] = (machine_kpis[col] - machine_kpis[col].mean()) / machine_kpis[col].std(ddof=0)\n",
    "machine_kpis['instability_score'] = machine_kpis[[\n",
    "    'delay_rate_pct_z', 'avg_schedule_deviation_min_z', 'energy_intensity_z'\n",
    "]].sum(axis=1)\n",
    "\n",
    "benchmark_view = machine_kpis[[\n",
    "    'jobs',\n",
    "    'delay_rate_pct',\n",
    "    'avg_schedule_deviation_min',\n",
    "    'avg_efficiency_category',\n",
    "    'energy_intensity',\n",
    "    'instability_score'\n",
    "]].sort_values('instability_score', ascending=False).round(3)\n",
    "\n",
    "print('\\nMachine benchmark (most unstable first):')\n",
    "print(benchmark_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f96f79",
   "metadata": {},
   "source": [
    "## Phase 2 - Operational Targets\n",
    "\n",
    "### Objective A: Delay Risk\n",
    "\n",
    "Binary target definition:\n",
    "- `delay_target = 1` for `Job_Status == 'Delayed'`\n",
    "- `delay_target = 0` for `Job_Status == 'Completed'`\n",
    "\n",
    "Diagnostic question:\n",
    "- Which operational factors are associated with higher delay probability?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11263edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline delay rate (Delayed vs Completed scope): 22.73%\n",
      "Rows used: 871\n",
      "\n",
      "Delay risk by Machine_ID (min 25 jobs):\n",
      "            jobs  delay_rate_pct  lift_vs_baseline_pp\n",
      "Machine_ID                                           \n",
      "M05          172           27.91                 5.17\n",
      "M02          189           22.75                 0.02\n",
      "M04          164           21.95                -0.78\n",
      "M03          157           21.66                -1.08\n",
      "M01          189           19.58                -3.16\n",
      "\n",
      "Delay risk by Operation_Type (min 25 jobs):\n",
      "                jobs  delay_rate_pct  lift_vs_baseline_pp\n",
      "Operation_Type                                           \n",
      "Grinding         183           25.14                 2.40\n",
      "Lathe            181           24.31                 1.58\n",
      "Milling          174           22.99                 0.26\n",
      "Drilling         168           22.02                -0.71\n",
      "Additive         165           18.79                -3.94\n",
      "\n",
      "Delay risk by Optimization_Category (min 25 jobs):\n",
      "                       jobs  delay_rate_pct  lift_vs_baseline_pp\n",
      "Optimization_Category                                           \n",
      "Low Efficiency          521            38.0                15.27\n",
      "High Efficiency         161             0.0               -22.73\n",
      "Moderate Efficiency     183             0.0               -22.73\n",
      "\n",
      "Delay risk profile for Processing_Time:\n",
      "                jobs  feature_mean  delay_rate_pct\n",
      "bucket                                            \n",
      "(19.999, 47.0]   222         33.54           22.97\n",
      "(47.0, 73.0]     217         60.74           22.12\n",
      "(73.0, 96.0]     218         84.74           22.02\n",
      "(96.0, 120.0]    214        107.56           23.83\n",
      "\n",
      "Delay risk profile for Energy_Consumption:\n",
      "                 jobs  feature_mean  delay_rate_pct\n",
      "bucket                                             \n",
      "(2.009, 5.42]     219          3.72           23.29\n",
      "(5.42, 8.66]      220          7.05           21.36\n",
      "(8.66, 11.615]    214         10.07           21.50\n",
      "(11.615, 14.98]   218         13.25           24.77\n",
      "\n",
      "Delay risk profile for Machine_Availability:\n",
      "                jobs  feature_mean  delay_rate_pct\n",
      "bucket                                            \n",
      "(79.999, 84.0]   232         81.80           24.14\n",
      "(84.0, 89.0]     217         87.11           18.43\n",
      "(89.0, 94.0]     213         91.84           25.82\n",
      "(94.0, 99.0]     209         96.83           22.49\n",
      "\n",
      "Delay risk profile for Material_Used:\n",
      "                            jobs  feature_mean  delay_rate_pct\n",
      "bucket                                                        \n",
      "(1.0090000000000001, 2.04]   219          1.53           22.37\n",
      "(2.04, 3.11]                 218          2.56           22.94\n",
      "(3.11, 4.045]                216          3.54           20.83\n",
      "(4.045, 5.0]                 218          4.51           24.77\n",
      "\n",
      "Delay risk profile for scheduled_duration_min:\n",
      "                jobs  feature_mean  delay_rate_pct\n",
      "bucket                                            \n",
      "(19.999, 47.0]   222         33.54           22.97\n",
      "(47.0, 73.0]     217         60.74           22.12\n",
      "(73.0, 96.0]     218         84.74           22.02\n",
      "(96.0, 120.0]    214        107.56           23.83\n",
      "\n",
      "Numeric feature correlation with delay_target (absolute strength sorted):\n",
      "                  feature  corr_with_delay_target\n",
      "2    Machine_Availability                   0.017\n",
      "3           Material_Used                   0.010\n",
      "1      Energy_Consumption                  -0.005\n",
      "0         Processing_Time                   0.004\n",
      "4  scheduled_duration_min                   0.004\n"
     ]
    }
   ],
   "source": [
    "# Scope: keep only completed vs delayed jobs for a clean binary target\n",
    "delay_risk_df = raw_data_df[raw_data_df['Job_Status'].isin(['Delayed', 'Completed'])].copy()\n",
    "delay_risk_df['delay_target'] = (delay_risk_df['Job_Status'] == 'Delayed').astype(int)\n",
    "\n",
    "# Build schedule-only numeric features (avoid using actual timestamps to reduce leakage)\n",
    "for col in ['Scheduled_Start', 'Scheduled_End']:\n",
    "    delay_risk_df[col] = pd.to_datetime(delay_risk_df[col], errors='coerce')\n",
    "delay_risk_df['scheduled_duration_min'] = (\n",
    "    delay_risk_df['Scheduled_End'] - delay_risk_df['Scheduled_Start']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "baseline_delay_pct = delay_risk_df['delay_target'].mean() * 100\n",
    "print(f'Baseline delay rate (Delayed vs Completed scope): {baseline_delay_pct:.2f}%')\n",
    "print(f'Rows used: {len(delay_risk_df)}')\n",
    "\n",
    "# 1) Categorical risk lift vs baseline\n",
    "def categorical_delay_lift(frame, col, min_jobs=25):\n",
    "    agg = frame.groupby(col).agg(\n",
    "        jobs=('delay_target', 'size'),\n",
    "        delay_rate=('delay_target', 'mean')\n",
    "    )\n",
    "    agg = agg[agg['jobs'] >= min_jobs].copy()\n",
    "    agg['delay_rate_pct'] = agg['delay_rate'] * 100\n",
    "    agg['lift_vs_baseline_pp'] = agg['delay_rate_pct'] - baseline_delay_pct\n",
    "    return agg.sort_values('delay_rate_pct', ascending=False)\n",
    "\n",
    "cat_features = ['Machine_ID', 'Operation_Type', 'Optimization_Category']\n",
    "for feat in cat_features:\n",
    "    print(f'\\nDelay risk by {feat} (min 25 jobs):')\n",
    "    print(categorical_delay_lift(delay_risk_df, feat).round(2)[['jobs', 'delay_rate_pct', 'lift_vs_baseline_pp']])\n",
    "\n",
    "# 2) Numeric directionality (correlation + quartile risk)\n",
    "def numeric_risk_profile(frame, col):\n",
    "    temp = frame[[col, 'delay_target']].dropna().copy()\n",
    "    corr = temp[col].corr(temp['delay_target'])\n",
    "\n",
    "    # Quartile delay rates show directional risk pattern\n",
    "    temp['bucket'] = pd.qcut(temp[col], q=4, duplicates='drop')\n",
    "    q = temp.groupby('bucket', observed=False).agg(\n",
    "        jobs=('delay_target', 'size'),\n",
    "        delay_rate=('delay_target', 'mean'),\n",
    "        feature_mean=(col, 'mean')\n",
    "    )\n",
    "    q['delay_rate_pct'] = q['delay_rate'] * 100\n",
    "    return corr, q[['jobs', 'feature_mean', 'delay_rate_pct']]\n",
    "\n",
    "num_features = [\n",
    "    'Processing_Time',\n",
    "    'Energy_Consumption',\n",
    "    'Machine_Availability',\n",
    "    'Material_Used',\n",
    "    'scheduled_duration_min'\n",
    "]\n",
    "\n",
    "numeric_summary = []\n",
    "for feat in num_features:\n",
    "    corr, quartile_table = numeric_risk_profile(delay_risk_df, feat)\n",
    "    numeric_summary.append({'feature': feat, 'corr_with_delay_target': corr})\n",
    "    print(f'\\nDelay risk profile for {feat}:')\n",
    "    print(quartile_table.round(2))\n",
    "\n",
    "numeric_summary_df = pd.DataFrame(numeric_summary).sort_values('corr_with_delay_target', key=lambda s: s.abs(), ascending=False)\n",
    "print('\\nNumeric feature correlation with delay_target (absolute strength sorted):')\n",
    "print(numeric_summary_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8177900",
   "metadata": {},
   "source": [
    "### Objective B: Efficiency Classification\n",
    "\n",
    "Multiclass target definition:\n",
    "- `efficiency_target` in `{Low, Moderate, High, Optimal}`\n",
    "\n",
    "Diagnostic question:\n",
    "- Which operational conditions are associated with higher efficiency categories?\n",
    "\n",
    "Note: this section is intentionally independent from Objective A (Delay Risk).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ea44c0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficiency class distribution:\n",
      "efficiency_target\n",
      "Low         650\n",
      "Moderate    183\n",
      "High        161\n",
      "Optimal       6\n",
      "\n",
      "Baseline High/Optimal rate: 16.70%\n",
      "\n",
      "High/Optimal efficiency by Machine_ID (min 25 jobs):\n",
      "            jobs  avg_efficiency_score  high_or_optimal_pct  \\\n",
      "Machine_ID                                                    \n",
      "M01          212                  1.59                19.34   \n",
      "M02          210                  1.55                19.52   \n",
      "M04          199                  1.54                17.59   \n",
      "M03          186                  1.49                13.98   \n",
      "M05          193                  1.42                12.44   \n",
      "\n",
      "            lift_vs_baseline_pp  \n",
      "Machine_ID                       \n",
      "M01                        2.64  \n",
      "M02                        2.82  \n",
      "M04                        0.89  \n",
      "M03                       -2.72  \n",
      "M05                       -4.26  \n",
      "\n",
      "High/Optimal efficiency by Operation_Type (min 25 jobs):\n",
      "                jobs  avg_efficiency_score  high_or_optimal_pct  \\\n",
      "Operation_Type                                                    \n",
      "Additive         190                  1.62                20.53   \n",
      "Lathe            212                  1.58                20.28   \n",
      "Drilling         189                  1.51                13.23   \n",
      "Milling          201                  1.50                15.92   \n",
      "Grinding         208                  1.40                13.46   \n",
      "\n",
      "                lift_vs_baseline_pp  \n",
      "Operation_Type                       \n",
      "Additive                       3.83  \n",
      "Lathe                          3.58  \n",
      "Drilling                      -3.47  \n",
      "Milling                       -0.78  \n",
      "Grinding                      -3.24  \n",
      "\n",
      "High/Optimal efficiency by Job_Status (min 25 jobs):\n",
      "            jobs  avg_efficiency_score  high_or_optimal_pct  \\\n",
      "Job_Status                                                    \n",
      "Completed    673                  1.78                24.81   \n",
      "Delayed      198                  1.00                 0.00   \n",
      "Failed       129                  1.00                 0.00   \n",
      "\n",
      "            lift_vs_baseline_pp  \n",
      "Job_Status                       \n",
      "Completed                  8.11  \n",
      "Delayed                  -16.70  \n",
      "Failed                   -16.70  \n",
      "\n",
      "Efficiency profile for Machine_Availability:\n",
      "                jobs  feature_mean  avg_efficiency_score  high_or_optimal_pct\n",
      "bucket                                                                       \n",
      "(79.999, 84.0]   266         81.78                  1.47                13.53\n",
      "(84.0, 89.0]     248         87.07                  1.55                16.53\n",
      "(89.0, 94.0]     248         91.88                  1.59                21.77\n",
      "(94.0, 99.0]     238         96.77                  1.48                15.13\n",
      "\n",
      "Efficiency profile for Energy_Consumption:\n",
      "                 jobs  feature_mean  avg_efficiency_score  high_or_optimal_pct\n",
      "bucket                                                                        \n",
      "(2.009, 5.398]    250          3.73                  1.66                 32.0\n",
      "(5.398, 8.56]     250          6.99                  1.69                 30.0\n",
      "(8.56, 11.672]    250         10.06                  1.41                  4.8\n",
      "(11.672, 14.98]   250         13.30                  1.33                  0.0\n",
      "\n",
      "Efficiency profile for Processing_Time:\n",
      "                jobs  feature_mean  avg_efficiency_score  high_or_optimal_pct\n",
      "bucket                                                                       \n",
      "(19.999, 48.0]   258         34.00                  1.57                18.22\n",
      "(48.0, 72.0]     244         60.84                  1.48                15.16\n",
      "(72.0, 96.0]     255         84.38                  1.58                18.43\n",
      "(96.0, 120.0]    243        108.02                  1.45                14.81\n",
      "\n",
      "Efficiency profile for Material_Used:\n",
      "                            jobs  feature_mean  avg_efficiency_score  \\\n",
      "bucket                                                                 \n",
      "(1.0090000000000001, 2.04]   253          1.53                  1.53   \n",
      "(2.04, 3.08]                 250          2.56                  1.53   \n",
      "(3.08, 4.043]                247          3.54                  1.54   \n",
      "(4.043, 5.0]                 250          4.50                  1.49   \n",
      "\n",
      "                            high_or_optimal_pct  \n",
      "bucket                                           \n",
      "(1.0090000000000001, 2.04]                18.97  \n",
      "(2.04, 3.08]                              16.40  \n",
      "(3.08, 4.043]                             16.60  \n",
      "(4.043, 5.0]                              14.80  \n",
      "\n",
      "Numeric feature correlation with efficiency score (absolute strength sorted):\n",
      "                feature  corr_with_efficiency_score\n",
      "1    Energy_Consumption                      -0.184\n",
      "2       Processing_Time                      -0.042\n",
      "3         Material_Used                      -0.019\n",
      "0  Machine_Availability                       0.003\n"
     ]
    }
   ],
   "source": [
    "# Objective B uses only efficiency outcomes and related operating conditions\n",
    "efficiency_df = raw_data_df.copy()\n",
    "\n",
    "label_map = {\n",
    "    'Low Efficiency': 'Low',\n",
    "    'Moderate Efficiency': 'Moderate',\n",
    "    'High Efficiency': 'High',\n",
    "    'Optimal Efficiency': 'Optimal'\n",
    "}\n",
    "class_order = ['Low', 'Moderate', 'High', 'Optimal']\n",
    "score_map = {'Low': 1, 'Moderate': 2, 'High': 3, 'Optimal': 4}\n",
    "\n",
    "efficiency_df['efficiency_target'] = efficiency_df['Optimization_Category'].map(label_map)\n",
    "efficiency_df = efficiency_df[efficiency_df['efficiency_target'].notna()].copy()\n",
    "efficiency_df['efficiency_target'] = pd.Categorical(\n",
    "    efficiency_df['efficiency_target'], categories=class_order, ordered=True\n",
    ")\n",
    "efficiency_df['efficiency_score'] = efficiency_df['efficiency_target'].map(score_map).astype(int)\n",
    "\n",
    "print('Efficiency class distribution:')\n",
    "class_dist = efficiency_df['efficiency_target'].value_counts().reindex(class_order, fill_value=0)\n",
    "print(class_dist.to_string())\n",
    "\n",
    "# Collapse top classes for interpretable \"higher efficiency\" condition scoring\n",
    "efficiency_df['high_or_optimal'] = efficiency_df['efficiency_target'].isin(['High', 'Optimal'])\n",
    "baseline_high_optimal_pct = efficiency_df['high_or_optimal'].mean() * 100\n",
    "print(f'\\nBaseline High/Optimal rate: {baseline_high_optimal_pct:.2f}%')\n",
    "\n",
    "# 1) Categorical operational conditions -> High/Optimal lift\n",
    "def high_efficiency_lift(frame, col, min_jobs=25):\n",
    "    agg = frame.groupby(col).agg(\n",
    "        jobs=('high_or_optimal', 'size'),\n",
    "        high_or_optimal_rate=('high_or_optimal', 'mean'),\n",
    "        avg_efficiency_score=('efficiency_score', 'mean')\n",
    "    )\n",
    "    agg = agg[agg['jobs'] >= min_jobs].copy()\n",
    "    agg['high_or_optimal_pct'] = agg['high_or_optimal_rate'] * 100\n",
    "    agg['lift_vs_baseline_pp'] = agg['high_or_optimal_pct'] - baseline_high_optimal_pct\n",
    "    return agg.sort_values(['avg_efficiency_score', 'high_or_optimal_pct'], ascending=False)\n",
    "\n",
    "for feature in ['Machine_ID', 'Operation_Type', 'Job_Status']:\n",
    "    print(f'\\nHigh/Optimal efficiency by {feature} (min 25 jobs):')\n",
    "    print(high_efficiency_lift(efficiency_df, feature).round(2)[['jobs', 'avg_efficiency_score', 'high_or_optimal_pct', 'lift_vs_baseline_pp']])\n",
    "\n",
    "# 2) Numeric operating conditions -> monotonic trend checks\n",
    "def numeric_efficiency_profile(frame, col):\n",
    "    temp = frame[[col, 'efficiency_score', 'high_or_optimal']].dropna().copy()\n",
    "    corr = temp[col].corr(temp['efficiency_score'])\n",
    "    temp['bucket'] = pd.qcut(temp[col], q=4, duplicates='drop')\n",
    "    q = temp.groupby('bucket', observed=False).agg(\n",
    "        jobs=('efficiency_score', 'size'),\n",
    "        feature_mean=(col, 'mean'),\n",
    "        avg_efficiency_score=('efficiency_score', 'mean'),\n",
    "        high_or_optimal_pct=('high_or_optimal', lambda s: s.mean() * 100)\n",
    "    )\n",
    "    return corr, q\n",
    "\n",
    "numeric_features = ['Machine_Availability', 'Energy_Consumption', 'Processing_Time', 'Material_Used']\n",
    "correlation_rows = []\n",
    "for feature in numeric_features:\n",
    "    corr, profile = numeric_efficiency_profile(efficiency_df, feature)\n",
    "    correlation_rows.append({'feature': feature, 'corr_with_efficiency_score': corr})\n",
    "    print(f'\\nEfficiency profile for {feature}:')\n",
    "    print(profile.round(2))\n",
    "\n",
    "correlation_table = pd.DataFrame(correlation_rows).sort_values(\n",
    "    'corr_with_efficiency_score', key=lambda s: s.abs(), ascending=False\n",
    ")\n",
    "print('\\nNumeric feature correlation with efficiency score (absolute strength sorted):')\n",
    "print(correlation_table.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c695636a",
   "metadata": {},
   "source": [
    "## Phase 3 - Engineer Meaningful Operational Metrics\n",
    "\n",
    "Convert raw scheduling timestamps into decision-relevant process metrics:\n",
    "\n",
    "- `schedule_deviation_min`\n",
    "- `start_delay_min`\n",
    "- `duration_variance_min`\n",
    "- `energy_per_unit_time`\n",
    "- `machine_delay_rate`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4a5982fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered process metrics (sample):\n",
      "  Job_ID Machine_ID  schedule_deviation_min  start_delay_min  \\\n",
      "0   J001        M01                     5.0              5.0   \n",
      "1   J002        M01                    10.0             10.0   \n",
      "2   J003        M04                     NaN              NaN   \n",
      "3   J004        M04                     5.0              5.0   \n",
      "4   J005        M01                     2.0              2.0   \n",
      "5   J006        M02                     3.0              3.0   \n",
      "6   J007        M04                     4.0              4.0   \n",
      "7   J008        M05                    -2.0             -2.0   \n",
      "8   J009        M02                     3.0              3.0   \n",
      "9   J010        M01                    24.0             24.0   \n",
      "\n",
      "   duration_variance_min  energy_per_unit_time  machine_delay_rate  \n",
      "0                    0.0              0.150263           47.641509  \n",
      "1                    0.0              0.083671           47.641509  \n",
      "2                    NaN              0.198393           46.733668  \n",
      "3                    0.0              0.117925           46.733668  \n",
      "4                    0.0              0.176739           47.641509  \n",
      "5                    0.0              0.138300           48.571429  \n",
      "6                    0.0              0.645455           46.733668  \n",
      "7                    0.0              0.175443           51.295337  \n",
      "8                    0.0              0.213571           48.571429  \n",
      "9                    0.0              0.135556           47.641509  \n",
      "\n",
      "Machine-level delay rate (%):\n",
      "  Machine_ID  machine_delay_rate  machine_jobs\n",
      "4        M05               51.30           193\n",
      "1        M02               48.57           210\n",
      "2        M03               48.39           186\n",
      "0        M01               47.64           212\n",
      "3        M04               46.73           199\n"
     ]
    }
   ],
   "source": [
    "# Base frame for feature engineering\n",
    "process_metrics_df = raw_data_df.copy()\n",
    "\n",
    "# Parse schedule/actual timestamps\n",
    "time_cols = ['Scheduled_Start', 'Scheduled_End', 'Actual_Start', 'Actual_End']\n",
    "for col in time_cols:\n",
    "    process_metrics_df[col] = pd.to_datetime(process_metrics_df[col], errors='coerce')\n",
    "\n",
    "# Core duration terms (minutes)\n",
    "process_metrics_df['scheduled_duration_min'] = (\n",
    "    process_metrics_df['Scheduled_End'] - process_metrics_df['Scheduled_Start']\n",
    ").dt.total_seconds() / 60\n",
    "process_metrics_df['actual_duration_min'] = (\n",
    "    process_metrics_df['Actual_End'] - process_metrics_df['Actual_Start']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# 1) Schedule deviation: end-time slip relative to plan\n",
    "process_metrics_df['schedule_deviation_min'] = (\n",
    "    process_metrics_df['Actual_End'] - process_metrics_df['Scheduled_End']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# 2) Start delay: start-time slip relative to plan\n",
    "process_metrics_df['start_delay_min'] = (\n",
    "    process_metrics_df['Actual_Start'] - process_metrics_df['Scheduled_Start']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# 3) Duration variance: execution duration difference vs plan\n",
    "process_metrics_df['duration_variance_min'] = (\n",
    "    process_metrics_df['actual_duration_min'] - process_metrics_df['scheduled_duration_min']\n",
    ")\n",
    "\n",
    "# 4) Energy per unit time: energy intensity using actual duration where available\n",
    "process_metrics_df['run_time_for_energy_min'] = process_metrics_df['actual_duration_min'].where(\n",
    "    process_metrics_df['actual_duration_min'] > 0,\n",
    "    process_metrics_df['Processing_Time']\n",
    ")\n",
    "process_metrics_df['energy_per_unit_time'] = (\n",
    "    process_metrics_df['Energy_Consumption'] / process_metrics_df['run_time_for_energy_min']\n",
    ")\n",
    "\n",
    "# Operational delay flag used to compute machine-level delay rate\n",
    "process_metrics_df['delayed_flag'] = (\n",
    "    process_metrics_df['Job_Status'].eq('Delayed')\n",
    "    | (process_metrics_df['schedule_deviation_min'] > 0)\n",
    "    | (process_metrics_df['start_delay_min'] > 0)\n",
    ")\n",
    "\n",
    "# 5) Machine-level delay rate\n",
    "machine_performance_df = process_metrics_df.groupby('Machine_ID').agg(\n",
    "    machine_delay_rate=('delayed_flag', 'mean'),\n",
    "    machine_jobs=('Job_ID', 'count')\n",
    ").reset_index()\n",
    "machine_performance_df['machine_delay_rate'] = machine_performance_df['machine_delay_rate'] * 100\n",
    "\n",
    "# Attach machine-level signal back to each job row\n",
    "process_metrics_df = process_metrics_df.merge(\n",
    "    machine_performance_df[['Machine_ID', 'machine_delay_rate']],\n",
    "    on='Machine_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "engineered_metric_cols = [\n",
    "    'Job_ID',\n",
    "    'Machine_ID',\n",
    "    'schedule_deviation_min',\n",
    "    'start_delay_min',\n",
    "    'duration_variance_min',\n",
    "    'energy_per_unit_time',\n",
    "    'machine_delay_rate'\n",
    "]\n",
    "\n",
    "print('Engineered process metrics (sample):')\n",
    "print(process_metrics_df[engineered_metric_cols].head(10))\n",
    "\n",
    "print('\\nMachine-level delay rate (%):')\n",
    "print(machine_performance_df.sort_values('machine_delay_rate', ascending=False).round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6023f666",
   "metadata": {},
   "source": [
    "## Phase 4 - Model for Insight, Not Just Prediction\n",
    "\n",
    "Objective: use interpretable models to understand operational drivers, not only predict outcomes.\n",
    "\n",
    "Questions answered:\n",
    "- Which variables most influence delay?\n",
    "- Does machine availability matter more than processing time?\n",
    "- Is energy intensity correlated with low efficiency?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1267018a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay model log-loss: 0.5358\n",
      "\n",
      "Delay model standardized coefficients (magnitude ranked):\n",
      "                feature  std_coef  odds_ratio_per_1sd\n",
      "0  Machine_Availability    0.0387              1.0394\n",
      "4  energy_per_unit_time    0.0309              1.0314\n",
      "3    Energy_Consumption   -0.0270              0.9733\n",
      "1       Processing_Time    0.0264              1.0268\n",
      "2         Material_Used    0.0232              1.0235\n",
      "\n",
      "Delay model permutation importance (higher delta = more influence):\n",
      "                feature  perm_importance_logloss_delta\n",
      "0  Machine_Availability                        0.00031\n",
      "4  energy_per_unit_time                        0.00028\n",
      "2         Material_Used                        0.00012\n",
      "3    Energy_Consumption                        0.00011\n",
      "1       Processing_Time                        0.00008\n",
      "\n",
      "Availability vs Processing_Time influence (delay model):\n",
      "Machine_Availability rank: 1\n",
      "Processing_Time rank: 5\n",
      "\n",
      "Low-efficiency model log-loss: 0.6455\n",
      "\n",
      "Low-efficiency model standardized coefficients (magnitude ranked):\n",
      "                feature  std_coef  odds_ratio_low_eff_per_1sd\n",
      "2       Processing_Time    0.1326                      1.1417\n",
      "1  Machine_Availability    0.0308                      1.0313\n",
      "0  energy_per_unit_time    0.0181                      1.0182\n",
      "3         Material_Used    0.0029                      1.0029\n",
      "\n",
      "Low-efficiency model permutation importance (higher delta = more influence):\n",
      "                feature  perm_importance_logloss_delta\n",
      "2       Processing_Time                        0.00429\n",
      "1  Machine_Availability                        0.00017\n",
      "0  energy_per_unit_time                        0.00006\n",
      "3         Material_Used                        0.00001\n",
      "\n",
      "Energy intensity correlation with low efficiency target: -0.0345\n",
      "\n",
      "Average energy intensity by efficiency class:\n",
      "Optimization_Category\n",
      "Moderate Efficiency    0.2047\n",
      "Low Efficiency         0.1458\n",
      "High Efficiency        0.1001\n",
      "Optimal Efficiency     0.0288\n",
      "Name: energy_per_unit_time, dtype: float64\n",
      "\n",
      "Operational interpretation:\n",
      "- Strongest modeled delay driver in this feature set: Machine_Availability.\n",
      "- Machine availability matters more than processing time for delay risk (by permutation rank).\n",
      "- Energy intensity is negatively correlated with low efficiency risk.\n",
      "- Strongest modeled low-efficiency driver in this feature set: Processing_Time.\n"
     ]
    }
   ],
   "source": [
    "# Use Phase 3 engineered metrics when available; otherwise create minimal equivalents\n",
    "if 'process_metrics_df' in globals():\n",
    "    model_base_df = process_metrics_df.copy()\n",
    "else:\n",
    "    model_base_df = raw_data_df.copy()\n",
    "    for col in ['Scheduled_Start', 'Scheduled_End', 'Actual_Start', 'Actual_End']:\n",
    "        model_base_df[col] = pd.to_datetime(model_base_df[col], errors='coerce')\n",
    "    model_base_df['scheduled_duration_min'] = (\n",
    "        model_base_df['Scheduled_End'] - model_base_df['Scheduled_Start']\n",
    "    ).dt.total_seconds() / 60\n",
    "    model_base_df['actual_duration_min'] = (\n",
    "        model_base_df['Actual_End'] - model_base_df['Actual_Start']\n",
    "    ).dt.total_seconds() / 60\n",
    "    model_base_df['schedule_deviation_min'] = (\n",
    "        model_base_df['Actual_End'] - model_base_df['Scheduled_End']\n",
    "    ).dt.total_seconds() / 60\n",
    "    model_base_df['start_delay_min'] = (\n",
    "        model_base_df['Actual_Start'] - model_base_df['Scheduled_Start']\n",
    "    ).dt.total_seconds() / 60\n",
    "    model_base_df['run_time_for_energy_min'] = model_base_df['actual_duration_min'].where(\n",
    "        model_base_df['actual_duration_min'] > 0, model_base_df['Processing_Time']\n",
    "    )\n",
    "    model_base_df['energy_per_unit_time'] = (\n",
    "        model_base_df['Energy_Consumption'] / model_base_df['run_time_for_energy_min']\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# Minimal logistic regression (NumPy)\n",
    "# -----------------------------\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -30, 30)\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def fit_logistic_regression(X, y, lr=0.05, epochs=4000, l2=0.01):\n",
    "    n_rows, n_cols = X.shape\n",
    "    w = np.zeros(n_cols)\n",
    "    b = 0.0\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        p = sigmoid(X @ w + b)\n",
    "        error = p - y\n",
    "\n",
    "        grad_w = (X.T @ error) / n_rows + l2 * w\n",
    "        grad_b = error.mean()\n",
    "\n",
    "        w -= lr * grad_w\n",
    "        b -= lr * grad_b\n",
    "\n",
    "    return w, b\n",
    "\n",
    "def log_loss(y_true, y_prob):\n",
    "    eps = 1e-9\n",
    "    y_prob = np.clip(y_prob, eps, 1 - eps)\n",
    "    return -np.mean(y_true * np.log(y_prob) + (1 - y_true) * np.log(1 - y_prob))\n",
    "\n",
    "def permutation_importance_logloss(X, y, feature_names, w, b, n_repeats=20, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    base_probs = sigmoid(X @ w + b)\n",
    "    base_loss = log_loss(y, base_probs)\n",
    "\n",
    "    rows = []\n",
    "    for j, feat in enumerate(feature_names):\n",
    "        deltas = []\n",
    "        for _ in range(n_repeats):\n",
    "            X_perm = X.copy()\n",
    "            X_perm[:, j] = rng.permutation(X_perm[:, j])\n",
    "            perm_probs = sigmoid(X_perm @ w + b)\n",
    "            deltas.append(log_loss(y, perm_probs) - base_loss)\n",
    "        rows.append((feat, float(np.mean(deltas))))\n",
    "\n",
    "    out = pd.DataFrame(rows, columns=['feature', 'perm_importance_logloss_delta'])\n",
    "    return out.sort_values('perm_importance_logloss_delta', ascending=False)\n",
    "\n",
    "# -----------------------------\n",
    "# A) Delay driver model (Delayed vs Completed only)\n",
    "# -----------------------------\n",
    "delay_model_df = model_base_df[model_base_df['Job_Status'].isin(['Delayed', 'Completed'])].copy()\n",
    "delay_model_df['delay_target'] = (delay_model_df['Job_Status'] == 'Delayed').astype(int)\n",
    "\n",
    "# Use pre-execution features only (avoid leakage from actual start/end deviation fields)\n",
    "delay_features = [\n",
    "    'Machine_Availability',\n",
    "    'Processing_Time',\n",
    "    'Material_Used',\n",
    "    'Energy_Consumption',\n",
    "    'energy_per_unit_time'\n",
    "]\n",
    "delay_model_df = delay_model_df.dropna(subset=delay_features + ['delay_target']).copy()\n",
    "\n",
    "X_delay_raw = delay_model_df[delay_features].astype(float).to_numpy()\n",
    "y_delay = delay_model_df['delay_target'].astype(float).to_numpy()\n",
    "\n",
    "# Standardize for coefficient comparability\n",
    "X_delay_mean = X_delay_raw.mean(axis=0)\n",
    "X_delay_std = X_delay_raw.std(axis=0)\n",
    "X_delay_std = np.where(X_delay_std == 0, 1, X_delay_std)\n",
    "X_delay = (X_delay_raw - X_delay_mean) / X_delay_std\n",
    "\n",
    "w_delay, b_delay = fit_logistic_regression(X_delay, y_delay)\n",
    "delay_probs = sigmoid(X_delay @ w_delay + b_delay)\n",
    "delay_loss = log_loss(y_delay, delay_probs)\n",
    "\n",
    "delay_coef_df = pd.DataFrame({\n",
    "    'feature': delay_features,\n",
    "    'std_coef': w_delay,\n",
    "    'odds_ratio_per_1sd': np.exp(w_delay),\n",
    "    'abs_std_coef': np.abs(w_delay)\n",
    "}).sort_values('abs_std_coef', ascending=False)\n",
    "\n",
    "delay_perm_df = permutation_importance_logloss(\n",
    "    X_delay, y_delay, delay_features, w_delay, b_delay, n_repeats=20, seed=42\n",
    ")\n",
    "\n",
    "print('Delay model log-loss:', round(delay_loss, 4))\n",
    "print('\\nDelay model standardized coefficients (magnitude ranked):')\n",
    "print(delay_coef_df[['feature', 'std_coef', 'odds_ratio_per_1sd']].round(4))\n",
    "print('\\nDelay model permutation importance (higher delta = more influence):')\n",
    "print(delay_perm_df.round(5))\n",
    "\n",
    "availability_rank = int(delay_perm_df.reset_index(drop=True).index[\n",
    "    delay_perm_df.reset_index(drop=True)['feature'].eq('Machine_Availability')\n",
    "][0]) + 1\n",
    "processing_rank = int(delay_perm_df.reset_index(drop=True).index[\n",
    "    delay_perm_df.reset_index(drop=True)['feature'].eq('Processing_Time')\n",
    "][0]) + 1\n",
    "\n",
    "print('\\nAvailability vs Processing_Time influence (delay model):')\n",
    "print(f'Machine_Availability rank: {availability_rank}')\n",
    "print(f'Processing_Time rank: {processing_rank}')\n",
    "\n",
    "# -----------------------------\n",
    "# B) Efficiency condition model (Low vs Not-Low)\n",
    "# -----------------------------\n",
    "eff_model_df = model_base_df.copy()\n",
    "eff_model_df = eff_model_df[eff_model_df['Optimization_Category'].notna()].copy()\n",
    "eff_model_df['low_eff_target'] = (eff_model_df['Optimization_Category'] == 'Low Efficiency').astype(int)\n",
    "\n",
    "eff_features = ['energy_per_unit_time', 'Machine_Availability', 'Processing_Time', 'Material_Used']\n",
    "eff_model_df = eff_model_df.dropna(subset=eff_features + ['low_eff_target']).copy()\n",
    "\n",
    "X_eff_raw = eff_model_df[eff_features].astype(float).to_numpy()\n",
    "y_eff = eff_model_df['low_eff_target'].astype(float).to_numpy()\n",
    "\n",
    "X_eff_mean = X_eff_raw.mean(axis=0)\n",
    "X_eff_std = X_eff_raw.std(axis=0)\n",
    "X_eff_std = np.where(X_eff_std == 0, 1, X_eff_std)\n",
    "X_eff = (X_eff_raw - X_eff_mean) / X_eff_std\n",
    "\n",
    "w_eff, b_eff = fit_logistic_regression(X_eff, y_eff)\n",
    "eff_probs = sigmoid(X_eff @ w_eff + b_eff)\n",
    "eff_loss = log_loss(y_eff, eff_probs)\n",
    "\n",
    "eff_coef_df = pd.DataFrame({\n",
    "    'feature': eff_features,\n",
    "    'std_coef': w_eff,\n",
    "    'odds_ratio_low_eff_per_1sd': np.exp(w_eff),\n",
    "    'abs_std_coef': np.abs(w_eff)\n",
    "}).sort_values('abs_std_coef', ascending=False)\n",
    "\n",
    "eff_perm_df = permutation_importance_logloss(\n",
    "    X_eff, y_eff, eff_features, w_eff, b_eff, n_repeats=20, seed=42\n",
    ")\n",
    "\n",
    "energy_corr = eff_model_df['energy_per_unit_time'].corr(eff_model_df['low_eff_target'])\n",
    "energy_by_class = eff_model_df.groupby('Optimization_Category')['energy_per_unit_time'].mean().sort_values(ascending=False)\n",
    "\n",
    "print('\\nLow-efficiency model log-loss:', round(eff_loss, 4))\n",
    "print('\\nLow-efficiency model standardized coefficients (magnitude ranked):')\n",
    "print(eff_coef_df[['feature', 'std_coef', 'odds_ratio_low_eff_per_1sd']].round(4))\n",
    "print('\\nLow-efficiency model permutation importance (higher delta = more influence):')\n",
    "print(eff_perm_df.round(5))\n",
    "print('\\nEnergy intensity correlation with low efficiency target:', round(float(energy_corr), 4))\n",
    "print('\\nAverage energy intensity by efficiency class:')\n",
    "print(energy_by_class.round(4))\n",
    "\n",
    "# Operational interpretation summary\n",
    "most_delay_driver = delay_perm_df.iloc[0]['feature']\n",
    "most_low_eff_driver = eff_perm_df.iloc[0]['feature']\n",
    "\n",
    "print('\\nOperational interpretation:')\n",
    "print(f'- Strongest modeled delay driver in this feature set: {most_delay_driver}.')\n",
    "if availability_rank < processing_rank:\n",
    "    print('- Machine availability matters more than processing time for delay risk (by permutation rank).')\n",
    "elif availability_rank > processing_rank:\n",
    "    print('- Processing time matters more than machine availability for delay risk (by permutation rank).')\n",
    "else:\n",
    "    print('- Machine availability and processing time are similarly ranked for delay risk.')\n",
    "\n",
    "if energy_corr > 0:\n",
    "    print('- Energy intensity is positively correlated with low efficiency risk.')\n",
    "elif energy_corr < 0:\n",
    "    print('- Energy intensity is negatively correlated with low efficiency risk.')\n",
    "else:\n",
    "    print('- Energy intensity shows near-zero linear correlation with low efficiency risk.')\n",
    "\n",
    "print(f'- Strongest modeled low-efficiency driver in this feature set: {most_low_eff_driver}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f60ac",
   "metadata": {},
   "source": [
    "## Phase 5 - Benchmark & Segment\n",
    "\n",
    "Convert model and metric outputs into decision-support views:\n",
    "\n",
    "- Rank machines by operational risk\n",
    "- Identify unstable operation types\n",
    "- Detect high-variance process segments\n",
    "- Flag conditions associated with low efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "80fc44e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine risk ranking (highest risk first):\n",
      "            jobs  delay_rate_pct  avg_schedule_deviation_min  \\\n",
      "Machine_ID                                                     \n",
      "M05          193          51.295                       5.343   \n",
      "M03          186          48.387                       4.338   \n",
      "M04          199          46.734                       4.677   \n",
      "M02          210          48.571                       4.196   \n",
      "M01          212          47.642                       3.868   \n",
      "\n",
      "            p90_start_delay_min  energy_intensity  risk_score  \n",
      "Machine_ID                                                     \n",
      "M05                        23.0             0.155       5.551  \n",
      "M03                        22.0             0.153       0.544  \n",
      "M04                        23.0             0.147      -0.471  \n",
      "M02                        23.0             0.143      -1.174  \n",
      "M01                        19.0             0.145      -4.450  \n",
      "\n",
      "Unstable operation types (highest instability first):\n",
      "                jobs  delay_rate_pct  deviation_std  start_delay_std  \\\n",
      "Operation_Type                                                         \n",
      "Grinding         208          43.269         10.126           10.126   \n",
      "Milling          201          45.771          9.968            9.968   \n",
      "Drilling         189          52.381          9.272            9.272   \n",
      "Lathe            212          51.415          9.239            9.239   \n",
      "Additive         190          50.000          8.418            8.418   \n",
      "\n",
      "                p90_abs_deviation  instability_score  \n",
      "Operation_Type                                        \n",
      "Grinding                     24.0              2.125  \n",
      "Milling                      23.0              1.743  \n",
      "Drilling                     22.0              0.775  \n",
      "Lathe                        21.0             -0.189  \n",
      "Additive                     19.0             -4.454  \n",
      "\n",
      "High-variance process segments (Machine x Operation):\n",
      "   Machine_ID Operation_Type  jobs  variance_index  schedule_deviation_std  \\\n",
      "24        M05        Milling    45          24.450                  12.225   \n",
      "12        M03       Grinding    36          23.761                  11.881   \n",
      "18        M04          Lathe    38          22.358                  11.179   \n",
      "17        M04       Grinding    43          21.610                  10.805   \n",
      "16        M04       Drilling    39          20.970                  10.485   \n",
      "6         M02       Drilling    47          20.536                  10.268   \n",
      "3         M01          Lathe    33          19.520                   9.760   \n",
      "19        M04        Milling    43          19.426                   9.713   \n",
      "7         M02       Grinding    39          19.364                   9.682   \n",
      "5         M02       Additive    40          19.210                   9.605   \n",
      "\n",
      "    start_delay_std  duration_variance_std  delay_rate_pct  \n",
      "24           12.225                    0.0          53.333  \n",
      "12           11.881                    0.0          50.000  \n",
      "18           11.179                    0.0          57.895  \n",
      "17           10.805                    0.0          34.884  \n",
      "16           10.485                    0.0          48.718  \n",
      "6            10.268                    0.0          57.447  \n",
      "3             9.760                    0.0          54.545  \n",
      "19            9.713                    0.0          46.512  \n",
      "7             9.682                    0.0          33.333  \n",
      "5             9.605                    0.0          55.000  \n",
      "\n",
      "Low-efficiency baseline rate: 65.00%\n",
      "\n",
      "Low-efficiency condition flags by Machine_ID:\n",
      "            jobs  low_eff_pct  lift_vs_baseline_pp\n",
      "Machine_ID                                        \n",
      "M05          193        70.47                 5.47\n",
      "M02          210        65.24                 0.24\n",
      "M04          199        64.82                -0.18\n",
      "M03          186        64.52                -0.48\n",
      "M01          212        60.38                -4.62\n",
      "\n",
      "Low-efficiency condition flags by Operation_Type:\n",
      "                jobs  low_eff_pct  lift_vs_baseline_pp\n",
      "Operation_Type                                        \n",
      "Grinding         208        73.08                 8.08\n",
      "Milling          201        67.16                 2.16\n",
      "Drilling         189        61.90                -3.10\n",
      "Lathe            212        61.79                -3.21\n",
      "Additive         190        60.53                -4.47\n",
      "\n",
      "Low-efficiency condition flags by availability_band:\n",
      "                   jobs  low_eff_pct  lift_vs_baseline_pp\n",
      "availability_band                                        \n",
      "(94.0, 99.0]        238        67.65                 2.65\n",
      "(79.999, 84.0]      266        66.54                 1.54\n",
      "(89.0, 94.0]        248        63.71                -1.29\n",
      "(84.0, 89.0]        248        62.10                -2.90\n",
      "\n",
      "Low-efficiency condition flags by energy_intensity_band:\n",
      "                       jobs  low_eff_pct  lift_vs_baseline_pp\n",
      "energy_intensity_band                                        \n",
      "(0.0163, 0.076]         250         69.6                  4.6\n",
      "(0.076, 0.12]           250         64.4                 -0.6\n",
      "(0.12, 0.184]           250         64.4                 -0.6\n",
      "(0.184, 0.682]          250         61.6                 -3.4\n"
     ]
    }
   ],
   "source": [
    "# Build decision-support tables from engineered metrics\n",
    "if 'process_metrics_df' in globals():\n",
    "    benchmark_df = process_metrics_df.copy()\n",
    "else:\n",
    "    benchmark_df = raw_data_df.copy()\n",
    "    for col in ['Scheduled_Start', 'Scheduled_End', 'Actual_Start', 'Actual_End']:\n",
    "        benchmark_df[col] = pd.to_datetime(benchmark_df[col], errors='coerce')\n",
    "    benchmark_df['scheduled_duration_min'] = (benchmark_df['Scheduled_End'] - benchmark_df['Scheduled_Start']).dt.total_seconds() / 60\n",
    "    benchmark_df['actual_duration_min'] = (benchmark_df['Actual_End'] - benchmark_df['Actual_Start']).dt.total_seconds() / 60\n",
    "    benchmark_df['schedule_deviation_min'] = (benchmark_df['Actual_End'] - benchmark_df['Scheduled_End']).dt.total_seconds() / 60\n",
    "    benchmark_df['start_delay_min'] = (benchmark_df['Actual_Start'] - benchmark_df['Scheduled_Start']).dt.total_seconds() / 60\n",
    "    benchmark_df['duration_variance_min'] = benchmark_df['actual_duration_min'] - benchmark_df['scheduled_duration_min']\n",
    "    benchmark_df['run_time_for_energy_min'] = benchmark_df['actual_duration_min'].where(\n",
    "        benchmark_df['actual_duration_min'] > 0, benchmark_df['Processing_Time']\n",
    "    )\n",
    "    benchmark_df['energy_per_unit_time'] = benchmark_df['Energy_Consumption'] / benchmark_df['run_time_for_energy_min']\n",
    "    benchmark_df['delayed_flag'] = (\n",
    "        benchmark_df['Job_Status'].eq('Delayed')\n",
    "        | (benchmark_df['schedule_deviation_min'] > 0)\n",
    "        | (benchmark_df['start_delay_min'] > 0)\n",
    "    )\n",
    "\n",
    "# --------------------------------\n",
    "# 1) Rank machines by operational risk\n",
    "# --------------------------------\n",
    "machine_risk_table = benchmark_df.groupby('Machine_ID').agg(\n",
    "    jobs=('Job_ID', 'count'),\n",
    "    delay_rate=('delayed_flag', 'mean'),\n",
    "    avg_schedule_deviation_min=('schedule_deviation_min', 'mean'),\n",
    "    p90_start_delay_min=('start_delay_min', lambda s: s.dropna().quantile(0.90) if s.notna().any() else np.nan),\n",
    "    energy_intensity=('energy_per_unit_time', 'mean')\n",
    ").copy()\n",
    "\n",
    "for col in ['delay_rate', 'avg_schedule_deviation_min', 'p90_start_delay_min', 'energy_intensity']:\n",
    "    std = machine_risk_table[col].std(ddof=0)\n",
    "    machine_risk_table[f'{col}_z'] = 0.0 if std == 0 else (machine_risk_table[col] - machine_risk_table[col].mean()) / std\n",
    "\n",
    "machine_risk_table['risk_score'] = machine_risk_table[[\n",
    "    'delay_rate_z',\n",
    "    'avg_schedule_deviation_min_z',\n",
    "    'p90_start_delay_min_z',\n",
    "    'energy_intensity_z'\n",
    "]].sum(axis=1)\n",
    "\n",
    "machine_risk_table['delay_rate_pct'] = machine_risk_table['delay_rate'] * 100\n",
    "machine_risk_table = machine_risk_table.sort_values('risk_score', ascending=False)\n",
    "\n",
    "print('Machine risk ranking (highest risk first):')\n",
    "print(machine_risk_table[[\n",
    "    'jobs', 'delay_rate_pct', 'avg_schedule_deviation_min', 'p90_start_delay_min', 'energy_intensity', 'risk_score'\n",
    "]].round(3))\n",
    "\n",
    "# --------------------------------\n",
    "# 2) Identify unstable operation types\n",
    "# --------------------------------\n",
    "operation_stability_table = benchmark_df.groupby('Operation_Type').agg(\n",
    "    jobs=('Job_ID', 'count'),\n",
    "    delay_rate=('delayed_flag', 'mean'),\n",
    "    deviation_std=('schedule_deviation_min', 'std'),\n",
    "    start_delay_std=('start_delay_min', 'std'),\n",
    "    p90_abs_deviation=('schedule_deviation_min', lambda s: s.dropna().abs().quantile(0.90) if s.notna().any() else np.nan)\n",
    ").copy()\n",
    "\n",
    "for col in ['delay_rate', 'deviation_std', 'start_delay_std', 'p90_abs_deviation']:\n",
    "    std = operation_stability_table[col].std(ddof=0)\n",
    "    operation_stability_table[f'{col}_z'] = 0.0 if std == 0 else (operation_stability_table[col] - operation_stability_table[col].mean()) / std\n",
    "\n",
    "operation_stability_table['instability_score'] = operation_stability_table[[\n",
    "    'delay_rate_z', 'deviation_std_z', 'start_delay_std_z', 'p90_abs_deviation_z'\n",
    "]].sum(axis=1)\n",
    "operation_stability_table['delay_rate_pct'] = operation_stability_table['delay_rate'] * 100\n",
    "operation_stability_table = operation_stability_table.sort_values('instability_score', ascending=False)\n",
    "\n",
    "print('\\nUnstable operation types (highest instability first):')\n",
    "print(operation_stability_table[[\n",
    "    'jobs', 'delay_rate_pct', 'deviation_std', 'start_delay_std', 'p90_abs_deviation', 'instability_score'\n",
    "]].round(3))\n",
    "\n",
    "# --------------------------------\n",
    "# 3) Detect high-variance process segments\n",
    "# --------------------------------\n",
    "segment_variance_table = benchmark_df.groupby(['Machine_ID', 'Operation_Type']).agg(\n",
    "    jobs=('Job_ID', 'count'),\n",
    "    schedule_deviation_std=('schedule_deviation_min', 'std'),\n",
    "    start_delay_std=('start_delay_min', 'std'),\n",
    "    duration_variance_std=('duration_variance_min', 'std'),\n",
    "    delay_rate=('delayed_flag', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "segment_variance_table = segment_variance_table[segment_variance_table['jobs'] >= 20].copy()\n",
    "segment_variance_table['delay_rate_pct'] = segment_variance_table['delay_rate'] * 100\n",
    "\n",
    "# Composite variance index: emphasis on timing variability\n",
    "segment_variance_table['variance_index'] = (\n",
    "    segment_variance_table['schedule_deviation_std'].fillna(0)\n",
    "    + segment_variance_table['start_delay_std'].fillna(0)\n",
    "    + 0.5 * segment_variance_table['duration_variance_std'].fillna(0)\n",
    ")\n",
    "\n",
    "high_variance_segments = segment_variance_table.sort_values(\n",
    "    ['variance_index', 'delay_rate_pct'], ascending=[False, False]\n",
    ").head(10)\n",
    "\n",
    "print('\\nHigh-variance process segments (Machine x Operation):')\n",
    "print(high_variance_segments[[\n",
    "    'Machine_ID', 'Operation_Type', 'jobs', 'variance_index', 'schedule_deviation_std',\n",
    "    'start_delay_std', 'duration_variance_std', 'delay_rate_pct'\n",
    "]].round(3))\n",
    "\n",
    "# --------------------------------\n",
    "# 4) Flag low-efficiency-associated conditions\n",
    "# --------------------------------\n",
    "low_eff_df = benchmark_df.copy()\n",
    "low_eff_df = low_eff_df[low_eff_df['Optimization_Category'].notna()].copy()\n",
    "low_eff_df['low_eff_flag'] = low_eff_df['Optimization_Category'].eq('Low Efficiency')\n",
    "low_eff_baseline_pct = low_eff_df['low_eff_flag'].mean() * 100\n",
    "\n",
    "# Create interpretable bins for continuous conditions\n",
    "low_eff_df['availability_band'] = pd.qcut(low_eff_df['Machine_Availability'], q=4, duplicates='drop')\n",
    "low_eff_df['energy_intensity_band'] = pd.qcut(low_eff_df['energy_per_unit_time'], q=4, duplicates='drop')\n",
    "\n",
    "def low_eff_condition_table(frame, col, min_jobs=25):\n",
    "    t = frame.groupby(col, observed=False).agg(\n",
    "        jobs=('low_eff_flag', 'size'),\n",
    "        low_eff_rate=('low_eff_flag', 'mean')\n",
    "    )\n",
    "    t = t[t['jobs'] >= min_jobs].copy()\n",
    "    t['low_eff_pct'] = t['low_eff_rate'] * 100\n",
    "    t['lift_vs_baseline_pp'] = t['low_eff_pct'] - low_eff_baseline_pct\n",
    "    return t.sort_values('low_eff_pct', ascending=False)\n",
    "\n",
    "print(f'\\nLow-efficiency baseline rate: {low_eff_baseline_pct:.2f}%')\n",
    "\n",
    "for cond_col in ['Machine_ID', 'Operation_Type', 'availability_band', 'energy_intensity_band']:\n",
    "    print(f'\\nLow-efficiency condition flags by {cond_col}:')\n",
    "    print(low_eff_condition_table(low_eff_df, cond_col).round(2)[['jobs', 'low_eff_pct', 'lift_vs_baseline_pp']])\n",
    "\n",
    "# Consolidated decision-support outputs for downstream use\n",
    "decision_support = {\n",
    "    'machine_risk_ranking': machine_risk_table,\n",
    "    'operation_instability': operation_stability_table,\n",
    "    'high_variance_segments': high_variance_segments,\n",
    "    'low_efficiency_conditions': {\n",
    "        'baseline_low_eff_pct': low_eff_baseline_pct\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d057ff",
   "metadata": {},
   "source": [
    "## Phase 6 - Translate to Actionable Insight\n",
    "\n",
    "Turn benchmark/model outputs into operational guidance statements that planners and supervisors can use directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee471464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actionable manufacturing insights:\n",
      "- Machine M05 shows 12.8% higher delay probability under low availability (6.3 pp lift; n_low=50, n_other=143).\n",
      "- Lathe operations exhibit the highest average schedule deviation (5.0 min; std 9.2).\n",
      "- Energy intensity to low-efficiency correlation is -0.035; highest-intensity quartile has 61.6% low-efficiency vs 69.6% in lowest (gap -8.0 pp).\n"
     ]
    }
   ],
   "source": [
    "# Narrative layer: convert metrics into concise operational insights\n",
    "insight_df = process_metrics_df.copy() if 'process_metrics_df' in globals() else raw_data_df.copy()\n",
    "\n",
    "# Ensure required engineered fields exist\n",
    "required_cols = {'schedule_deviation_min', 'start_delay_min', 'energy_per_unit_time', 'delayed_flag'}\n",
    "if not required_cols.issubset(insight_df.columns):\n",
    "    for col in ['Scheduled_Start', 'Scheduled_End', 'Actual_Start', 'Actual_End']:\n",
    "        insight_df[col] = pd.to_datetime(insight_df[col], errors='coerce')\n",
    "    insight_df['actual_duration_min'] = (insight_df['Actual_End'] - insight_df['Actual_Start']).dt.total_seconds() / 60\n",
    "    insight_df['schedule_deviation_min'] = (insight_df['Actual_End'] - insight_df['Scheduled_End']).dt.total_seconds() / 60\n",
    "    insight_df['start_delay_min'] = (insight_df['Actual_Start'] - insight_df['Scheduled_Start']).dt.total_seconds() / 60\n",
    "    insight_df['run_time_for_energy_min'] = insight_df['actual_duration_min'].where(\n",
    "        insight_df['actual_duration_min'] > 0, insight_df['Processing_Time']\n",
    "    )\n",
    "    insight_df['energy_per_unit_time'] = insight_df['Energy_Consumption'] / insight_df['run_time_for_energy_min']\n",
    "    insight_df['delayed_flag'] = (\n",
    "        insight_df['Job_Status'].eq('Delayed')\n",
    "        | (insight_df['schedule_deviation_min'] > 0)\n",
    "        | (insight_df['start_delay_min'] > 0)\n",
    "    )\n",
    "\n",
    "# 1) Machine + availability delay lift statement\n",
    "availability_cutoff = insight_df['Machine_Availability'].quantile(0.25)\n",
    "insight_df['low_availability_flag'] = insight_df['Machine_Availability'] <= availability_cutoff\n",
    "\n",
    "machine_availability_delay = insight_df.groupby(['Machine_ID', 'low_availability_flag']).agg(\n",
    "    delay_rate=('delayed_flag', 'mean'),\n",
    "    jobs=('Job_ID', 'count')\n",
    ").reset_index()\n",
    "\n",
    "pivot_delay = machine_availability_delay.pivot(index='Machine_ID', columns='low_availability_flag', values='delay_rate')\n",
    "pivot_jobs = machine_availability_delay.pivot(index='Machine_ID', columns='low_availability_flag', values='jobs')\n",
    "\n",
    "valid = pivot_delay.dropna().copy()\n",
    "valid['delay_lift_pct'] = ((valid[True] - valid[False]) / valid[False].replace(0, np.nan)) * 100\n",
    "valid['abs_pp_lift'] = (valid[True] - valid[False]) * 100\n",
    "valid = valid.replace([np.inf, -np.inf], np.nan).dropna(subset=['delay_lift_pct'])\n",
    "\n",
    "if len(valid) > 0:\n",
    "    top_machine = valid['delay_lift_pct'].sort_values(ascending=False).index[0]\n",
    "    top_rel_lift = valid.loc[top_machine, 'delay_lift_pct']\n",
    "    top_abs_lift = valid.loc[top_machine, 'abs_pp_lift']\n",
    "    low_jobs = int(pivot_jobs.loc[top_machine, True]) if True in pivot_jobs.columns else 0\n",
    "    high_jobs = int(pivot_jobs.loc[top_machine, False]) if False in pivot_jobs.columns else 0\n",
    "    machine_availability_insight = (\n",
    "        f\"Machine {top_machine} shows {top_rel_lift:.1f}% higher delay probability under low availability \"\n",
    "        f\"({top_abs_lift:.1f} pp lift; n_low={low_jobs}, n_other={high_jobs}).\"\n",
    "    )\n",
    "else:\n",
    "    machine_availability_insight = 'Machine-level low-availability delay lift could not be estimated with current data coverage.'\n",
    "\n",
    "# 2) Operation type instability statement\n",
    "operation_deviation = insight_df.groupby('Operation_Type').agg(\n",
    "    avg_schedule_deviation=('schedule_deviation_min', 'mean'),\n",
    "    deviation_std=('schedule_deviation_min', 'std'),\n",
    "    jobs=('Job_ID', 'count')\n",
    ").dropna(subset=['avg_schedule_deviation'])\n",
    "\n",
    "worst_operation = operation_deviation['avg_schedule_deviation'].sort_values(ascending=False).index[0]\n",
    "worst_dev = operation_deviation.loc[worst_operation, 'avg_schedule_deviation']\n",
    "worst_dev_std = operation_deviation.loc[worst_operation, 'deviation_std']\n",
    "operation_insight = (\n",
    "    f\"{worst_operation} operations exhibit the highest average schedule deviation \"\n",
    "    f\"({worst_dev:.1f} min; std {worst_dev_std:.1f}).\"\n",
    ")\n",
    "\n",
    "# 3) Energy intensity vs low efficiency statement\n",
    "eff_frame = insight_df[insight_df['Optimization_Category'].notna()].copy()\n",
    "eff_frame['low_eff_flag'] = eff_frame['Optimization_Category'].eq('Low Efficiency').astype(int)\n",
    "energy_corr = eff_frame['energy_per_unit_time'].corr(eff_frame['low_eff_flag'])\n",
    "\n",
    "energy_band = pd.qcut(eff_frame['energy_per_unit_time'], q=4, duplicates='drop')\n",
    "band_table = eff_frame.groupby(energy_band, observed=False).agg(\n",
    "    jobs=('low_eff_flag', 'size'),\n",
    "    low_eff_rate=('low_eff_flag', 'mean')\n",
    ")\n",
    "band_table['low_eff_pct'] = band_table['low_eff_rate'] * 100\n",
    "\n",
    "high_band_pct = band_table['low_eff_pct'].iloc[-1]\n",
    "low_band_pct = band_table['low_eff_pct'].iloc[0]\n",
    "band_gap = high_band_pct - low_band_pct\n",
    "\n",
    "energy_insight = (\n",
    "    f\"Energy intensity to low-efficiency correlation is {energy_corr:.3f}; \"\n",
    "    f\"highest-intensity quartile has {high_band_pct:.1f}% low-efficiency vs {low_band_pct:.1f}% in lowest \"\n",
    "    f\"(gap {band_gap:.1f} pp).\"\n",
    ")\n",
    "\n",
    "# Consolidated actionable insights\n",
    "actionable_insights = [\n",
    "    machine_availability_insight,\n",
    "    operation_insight,\n",
    "    energy_insight\n",
    "]\n",
    "\n",
    "print('Actionable manufacturing insights:')\n",
    "for line in actionable_insights:\n",
    "    print(f'- {line}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
